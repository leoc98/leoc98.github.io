
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Note · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Advance Algorithm DataStructure
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../advance%20algo&ds/note.md">
            
                <span>
            
                    
                    Note
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Angular
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../Angualr/note.html">
            
                <a href="../Angualr/note.html">
            
                    
                    Note
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    CNN
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../CNN/andrewNg.html">
            
                <a href="../CNN/andrewNg.html">
            
                    
                    Andrew Ng
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Distrubuted Algorithm
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../Distrubuted%20Algorithm/note.md">
            
                <span>
            
                    
                    Note
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../MISC/misc.html">
            
                <a href="../MISC/misc.html">
            
                    
                    MISC
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    NLP
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="1.7.1" data-path="note.html">
            
                <a href="note.html">
            
                    
                    Note
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    Nodejs
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../Nodejs/note.html">
            
                <a href="../Nodejs/note.html">
            
                    
                    Note
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <span>
            
                    
                    TODOLIST
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../TODOLIST/melbCourse.md">
            
                <span>
            
                    
                    Melb Course
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../TODOLIST/todo.md">
            
                <span>
            
                    
                    Todo
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" >
            
                <span>
            
                    
                    并发编程
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../并发编程/c++.html">
            
                <a href="../并发编程/c++.html">
            
                    
                    C
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Note</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="text-preprocessing">text preprocessing</h1>
<ul>
<li>words =&gt; sentence =&gt; documents =&gt; corpus(like wikipedia)</li>
<li>word token: each instance of a word</li>
<li>word type: distinct words<h2 id="reason">reason</h2>
language is compositional, to break long sentence into individual words for machine to process<h2 id="steps">steps</h2>
</li>
<li>remove unwanted formatting (e.g. HTML)</li>
<li>sentence segmentation: break documents into sentences</li>
<li>word wokenisation: break sentences into words</li>
<li>word normalisation: words =&gt; canonical forms (e.g. Hi =&gt; hi)</li>
<li>stopword removal: delete unwanted words</li>
</ul>
<h2 id="sentence-segmentation">Sentence segmentation</h2>
<p>use binary classifier to determine each segemntation flag (e.g. punchation)</p>
<ul>
<li>Features<ul>
<li>Look at the words before and after &quot;.&quot; </li>
<li>Word shapes:<ul>
<li>-Uppercase, lowercase,ALL CAPS, numbel</li>
<li>-Character length</li>
</ul>
</li>
</ul>
</li>
<li>Part-of-speech tags:<ul>
<li>Determiners tend to start a sentence</li>
</ul>
</li>
</ul>
<h2 id="word-tokenisation">Word Tokenisation</h2>
<p>Assumption: good vocabulary and lexicon</p>
<p>MaxMatch algorithm</p>
<p>a greedy match longest word in vocabulary</p>
<p>failed: &#x53BB;&#x4E70;/&#x65B0;&#x897F;&#x5170;/&#x82B1;;&#x53BB;&#x4E70;&#x65B0;/&#x897F;&#x5170;&#x82B1;</p>
<h3 id="subword-tokenisation">Subword Tokenisation</h3>
<p>bring more meaningful word breakdown (e.g. colourless =&gt; colour less)</p>
<h4 id="byte-pair-encoding-bpe">Byte-pair encoding (BPE)</h4>
<p>to build a vocabulary by iterly find the words combination from most frequently to most rearly. <em>Use a threshold to seperate a valid vocabulary set to use.</em></p>
<p>Advantage:</p>
<ul>
<li>Data-informed tokenisation</li>
<li>Works for different languages (tokens)</li>
<li>Deals better with unknown words</li>
</ul>
<h3 id="word-normalisation">Word normalisation</h3>
<p>reduce the size of vocabulary</p>
<h4 id="morphology">Morphology</h4>
<ul>
<li>inflectional: not changing meaning<ul>
<li>Lemmatisation: remove all inflection</li>
</ul>
</li>
<li>derivational: <ul>
<li>suffix: change lexical category</li>
<li>prefix: change meaning but not change lexical category</li>
<li>Stemming: strips off all prefixes and suffixes<ul>
<li>good for information retrieval(searching)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="stopword-removal">Stopword removal</h2>
<p>def: stop word, a list of word that will be remove from vocabulary</p>
<h1 id="language-models">Language Models</h1>
<h2 id="seen-probability">Seen probability</h2>
<p>$P(sentence) = \prod_{i&lt;len(sentence)} P(w_i)$</p>
<h2 id="perplexity">Perplexity</h2>
<p>$$PP(sentence) = (\frac{1}{P(sentence)})^{ \frac{1}{m}}$$</p>
<p>$$log(PP) = -\frac{1}{m}log(P)$$</p>
<h2 id="n-grams">n-grams</h2>
<h3 id="markov-assumption">Markov Assumption</h3>
<p>$$P(w<em>i|w_1w_2...w</em>{i-1}) \approx P(w<em>{i-n+1}...w</em>{i-1}) $$</p>
<h3 id="maximun-likelihood-estimation">Maximun Likelihood Estimation</h3>
<p>unigram</p>
<p>$$P(w_i) = \frac{C(w_i)}{M}$$
n-gram($n&gt;1$)</p>
<p>$$P(w<em>{i-n+1}...w</em>{i-1}) = \frac{
C(w<em>{i-n+1}...w</em>{i})
}{
C(w<em>{i-n+1}...w</em>{i-1})
}$$</p>
<h3 id="smoothing">Smoothing</h3>
<p>avoid meet some events that have never met before</p>
<ul>
<li>Laplacian Smoothing $P(w<em>i) = \frac{
C(w</em>{i-n+1}...w<em>{i}) + \alpha
}{
C(w</em>{i-n+1}...w_{i-1}) + \alpha|V|
}$</li>
<li>Lidstone Smoothing $P(w_i) = \frac{
count(word) + \alpha
}{
word_token + word_type \times \alpha
}$</li>
<li>Absolute Discounting: take away fix probability from existed words to unseen words </li>
<li>Katz Backoff: take away fix probability from existed words and redistribute to unseen words<ol>
<li>get a fix count from existed words</li>
<li>distribute fix count by the portion of all unseen combination (where $C(w_{i-1},w_a) = 0$)<ul>
<li>$\frac{P(this)}{\sum<em>{C(w</em>{i-1},w<em>a) = 0} P(w</em>{a})}$</li>
<li>note that $P(w_i)$ is a backoff, which means it takes the probability of (n-1)-grams</li>
</ul>
</li>
</ol>
</li>
<li>Kneser-Ney Smoothing: redistribute probability mass based on the versatility (continuation probability) of the lower order n-gram<ol>
<li>get a fix count from existed words</li>
<li>distribute fix count by the portion of all existed conbination prefix count (<strong>unique count</strong>, where $count(w^{&apos;}<em>{i-1}:C(w^{&apos;}</em>{i-1}, w<em>i)&gt;0)$) divided all unseen combindation of their seen count (<strong>also unique count</strong>, where $\sum</em>{\underbrace{w<em>j:C(w</em>{i-1},w<em>{j})=0}</em>{all\ unseen\ combindation\ of\ w<em>{i-1}}} count(\underbrace{w_j:C(w</em>{j-1},w<em>{j}) &gt; 0}</em>{seen\ conbination\ count\ of\ w_j})$)<h3 id="interpolation">Interpolation</h3>
$$P<em>{IN}(w_i|w</em>{i-1},w_{i-2}) = \lambda_3 P_3 + \lambda_2 P_2 + \lambda_1 P_1$$
where $\sum \lambda_i = 1$, 
$P_i$ denotes i-grams probability,
$lambda$ is learned base on held out data</li>
</ol>
</li>
</ul>
<h1 id="text-classification">Text Classification</h1>
<h2 id="category">Category</h2>
<h3 id="topic-classification">Topic Classification</h3>
<ul>
<li>Motivation:library science, information retrieval</li>
<li>Classes: Topic categories, e.g.&#x201C;jobs&#x201D;, &#x201C;internationalnews&#x2019;</li>
<li>Features<ul>
<li>Unigram bag of words (BOW), with stop-words removed</li>
<li>Longer n-grams (bigrams, trigrams) for phrases</li>
</ul>
</li>
<li><p>Examples of corpora</p>
<ul>
<li>Reuters news corpus (RCV1; NLTK)</li>
<li>Pubmed abstracts</li>
<li>Tweets with hashtags<h3 id="sentiment-analysis">Sentiment Analysis</h3>
</li>
</ul>
</li>
<li><p>Motivation: opinion mining, business analytics</p>
</li>
<li>Classes: Positive/Negative/(Neutral)</li>
<li>Features<ul>
<li>N-grams</li>
<li>Polarity lexicons</li>
</ul>
</li>
<li>Examples of corpora<ul>
<li>Movie review dataset (in NLTK)</li>
<li>SEMEVAL Twitter polarity datasets</li>
</ul>
</li>
</ul>
<h3 id="native-language-identification">Native-Language Identification</h3>
<ul>
<li>Motivation: forensic linguistics, educational applications</li>
<li>Classes: first language of author (e.g. Indonesian)</li>
<li>Features<ul>
<li>Word Ngrams</li>
<li>Syntactic patterns (POS, parse trees)</li>
<li>Phonological features</li>
</ul>
</li>
</ul>
<h3 id="natural-language-inference">Natural Language Inference</h3>
<p>find relationship between two sentence.</p>
<ul>
<li>Motivation: language understanding</li>
<li>Classes:entailment, contradiction, neutral</li>
<li>Features<ul>
<li>Word overlap</li>
<li>Length difference between the sentences</li>
<li>N-grams</li>
</ul>
</li>
</ul>
<h2 id="build-text-classifier">Build text classifier</h2>
<ul>
<li>identify a task</li>
<li>collect appropriate corpus</li>
<li>carry out annotation</li>
<li>select features</li>
<li>choose algorithm</li>
<li>train model &amp; tune hyper parameter</li>
</ul>
<h3 id="algorithm">algorithm</h3>
<p>use SVM</p>
<ul>
<li>non-linear kernel trick works well for text</li>
<li>NLP has a good feature scaling</li>
<li>NLP dataset is large</li>
<li>NLP problems often involve large feature sets</li>
</ul>
<h1 id="part-of-speech-pos">Part of Speech (POS)</h1>
<p>for information extraction</p>
<h2 id="class">class</h2>
<ul>
<li>open: new words will be generated<ul>
<li>nouns</li>
<li>verbs</li>
<li>adjectives</li>
<li>adverbs</li>
</ul>
</li>
<li>closed: no new words<ul>
<li>prepositions(in, on, with, ...)</li>
<li>paricles:<ul>
<li>breushed himself <strong>off</strong></li>
</ul>
</li>
<li>determiners(a, an, the,... )</li>
<li>pronouns(I, me,my,...)</li>
<li>conjunctions(and, or, if,...)</li>
<li>modal verbs(can,could,should,must,...)</li>
</ul>
</li>
</ul>
<h2 id="tagsets">Tagsets</h2>
<p>...</p>
<h3 id="automiatic-tagger">automiatic Tagger</h3>
<ul>
<li>rule-based tagging<ul>
<li>find a list of possible tags for each word</li>
<li>apply rules to narrow down to a single tag </li>
</ul>
</li>
<li>unigram Tagger<ul>
<li>assign most common tag to each word type</li>
<li>model is a look-up table</li>
</ul>
</li>
<li>n-gram Tagger<ul>
<li>aparse issues (use backoff)</li>
</ul>
</li>
<li>classifier-based tagging<ul>
<li>use a classifier to tag each features</li>
<li>error propagation: wrong prediction infect next prediction</li>
</ul>
</li>
<li>hidden markov Models<ul>
<li>use a basic sequential model</li>
<li>takes into account the whole sequence (avoid error propagation) (call sequence labelling, structured prediction)</li>
<li>output independence assumption: ignored previous tags influence to current word<ul>
<li>$P(w|t) = \prod P(w_i|t_i)$</li>
</ul>
</li>
<li>markov assumption: tag can only relavant to previous tag<ul>
<li>$P(t) = \prod P(t<em>i|t</em>{i-1})$</li>
</ul>
</li>
<li>unable to track all possibility<ul>
<li>use viterbi algorithm</li>
<li>a dynamic programming way</li>
<li>$P(w|t)P(t) = \prod P(w<em>i|t_i)*max(P(t_i|t</em>{i-1})*s(t<em>{i-1}, w</em>{i-1}))$</li>
<li>where $s(t<em>{i-1}, w</em>{i-1})$ is the previous state that has been calculate (store in a table)</li>
<li>$O(t^2n)$, where t is the tagset size, n is the lenght of sequence</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="unkonwn-words">unkonwn words</h3>
<ul>
<li>use hapax legomena to guess</li>
<li>sub-word representations to capture morphology</li>
</ul>
<h1 id="deep-leanrning-for-nlp">Deep leanrning for NLP</h1>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Note","level":"1.7.1","depth":2,"next":{"title":"Nodejs","level":"1.8","depth":1,"ref":"","articles":[{"title":"Note","level":"1.8.1","depth":2,"path":"Nodejs/note.md","ref":"Nodejs/note.md","articles":[]}]},"previous":{"title":"NLP","level":"1.7","depth":1,"ref":"","articles":[{"title":"Note","level":"1.7.1","depth":2,"path":"NLP/note.md","ref":"NLP/note.md","articles":[]}]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"NLP/note.md","mtime":"2024-03-20T03:42:04.411Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-03-20T11:04:22.723Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

